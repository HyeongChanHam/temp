{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14b07ae-9304-486e-b5b5-bde410202c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/dro/temp/2d\n",
      "['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/omnisafe/venv/lib/python3.10/site-packages', '__editable__.omnisafe-0.5.1.dev27+g080e6b8.finder.__path_hook__', '/home/omnisafe/venv/lib/python3.10/site-packages/pytorch_lightning-2.4.0-py3.10.egg', '/home/omnisafe/venv/lib/python3.10/site-packages/pandas-2.0.3-py3.10-linux-x86_64.egg', '/work/DRO-EDL/1d/evidential-learning-pytorch']\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!export PYTHONPATH=$PYTHONPATH:$(pwd)/evidential-learning-pytorch\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/work/dro/temp/1d/evidential-learning-pytorch')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm, invgamma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import dblquad\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from edl_pytorch import NormalInvGamma, evidential_regression\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f23ec6-0a1f-4efd-b0d7-38bd54d9bc3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cart2polar(x,y):\n",
    "    r = (x**2 + y**2)**(1/2)\n",
    "    theta = np.arctan2(y,x)\n",
    "    return r , theta\n",
    "\n",
    "def polar2cart(r,theta):\n",
    "    x = r*np.cos(theta)\n",
    "    y = r*np.sin(theta)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656bfb3d-70b4-4d29-86a8-dba5ed6027ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    NormalInvGamma(64, 2),\n",
    ")\n",
    "model.load_state_dict(torch.load(f'uncertain_weights/{90}.pth', weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4928fd6-de8a-4d0b-8cb6-34c80a045011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NIG_sample(params):\n",
    "    mu_0, lambda_, alpha, beta = params\n",
    "    x_sigma2_dist = invgamma(alpha, scale=beta)\n",
    "    sigma2 = x_sigma2_dist.rvs(1)\n",
    "    x_mu_dist = norm(mu_0, np.sqrt(sigma2 / lambda_))\n",
    "    mu = x_mu_dist.rvs(1)\n",
    "    return np.array([mu[0], sigma2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77cf4dca-1595-440f-8047-8c1e61989bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_memory = dict()\n",
    "with open(f'../1d/a_memory_set/a_memory_{0.9}.pickle', 'rb') as f:\n",
    "    a_memory = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d368fff-566c-416e-a8d1-e719ff1836f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be143ed2acd548d9914a338a42f72522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Major Axis (a)', min=-100.0, step=1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def plot(x, y):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    print(x, y)\n",
    "    sample = [x, y]\n",
    "    input_data = torch.tensor(cart2polar(*sample), dtype=torch.float)[None,:]\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    x_params = [pred[0][0,0], pred[1][0,0], pred[2][0,0], pred[3][0,0]]\n",
    "    y_params = [pred[0][0,1], pred[1][0,1], pred[2][0,1], pred[3][0,1]]\n",
    "\n",
    "    \n",
    "    # ambiguity set\n",
    "    ## x axis\n",
    "    mu_0, lambda_, alpha, beta = x_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    x_mu_low, x_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    ## y axis\n",
    "    mu_0, lambda_, alpha, beta = y_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    y_mu_low, y_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    vertices = [(x_mu_low, y_mu_low), (x_mu_low, y_mu_high), (x_mu_high, y_mu_high), (x_mu_high, y_mu_low)]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    # sampling\n",
    "    for _ in range(500):\n",
    "        x_dist_params = NIG_sample(x_params)\n",
    "        y_dist_params = NIG_sample(y_params)\n",
    "\n",
    "        mean = np.array([x_dist_params[0], y_dist_params[0]])\n",
    "        cov = np.array([\n",
    "            [x_dist_params[1], 0],\n",
    "            [0, y_dist_params[1]]\n",
    "        ])\n",
    "\n",
    "\n",
    "        # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "        # 1-sigma 수준에서 타원의 축 반지름 계산\n",
    "        axis_lengths = np.sqrt(eigvals)\n",
    "\n",
    "        # 타원의 각도 계산 (라디안)\n",
    "        angle = np.arctan2(eigvecs[1, 0], eigvecs[0, 0])\n",
    "\n",
    "        # 타원 좌표 생성\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)\n",
    "        ellipse = np.array([axis_lengths[0] * np.cos(theta), axis_lengths[1] * np.sin(theta)])\n",
    "\n",
    "        # 타원의 회전 적용\n",
    "        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                                     [np.sin(angle), np.cos(angle)]])\n",
    "        rotated_ellipse = rotation_matrix @ ellipse\n",
    "\n",
    "        # 타원을 평균 좌표로 이동\n",
    "        ellipse_x, ellipse_y = rotated_ellipse[0] + mean[0], rotated_ellipse[1] + mean[1]\n",
    "        if (x_mu_low < mean[0] and mean[0] < x_mu_high) and (y_mu_low < mean[1] and mean[1] < y_mu_high):\n",
    "            color = 'lime'\n",
    "            alpha = 0.1\n",
    "            label = 'in ambiguity set'\n",
    "        else:\n",
    "            color = 'skyblue'\n",
    "            alpha = 0.8\n",
    "            label = 'out of ambiguity set'\n",
    "        plt.plot(ellipse_x, ellipse_y, color=color, alpha=alpha, label=label)\n",
    "    ax.add_patch(rectangle)\n",
    "\n",
    "    plt.scatter(*sample, color='g', label='Ground Truth')\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-100, 100)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))  # 중복 제거\n",
    "\n",
    "    # 고유한 레이블만 포함하는 legend 표시\n",
    "    plt.legend(unique_labels.values(), unique_labels.keys())   \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(\n",
    "        plot,\n",
    "        x=FloatSlider(min=-100, max=100, step=1, value=0, description='Major Axis (a)'),\n",
    "        y=FloatSlider(min=-100, max=100, step=1, value=0, description='Minor Axis (b)'),\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513b3a2c-12f2-4074-a65f-dd4ea94fcac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ellipse(mean, covariance, n_std=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    평균과 공분산 행렬을 사용하여 타원을 그립니다.\n",
    "\n",
    "    Parameters:\n",
    "    - mean: 1x2 배열, 타원의 중심 (평균 벡터)\n",
    "    - covariance: 2x2 배열, 공분산 행렬\n",
    "    - n_std: float, 타원의 크기를 결정하는 표준편차의 배수 (기본값: 2)\n",
    "    - ax: matplotlib 축 객체 (기본값: None)\n",
    "    - kwargs: matplotlib.patches.Ellipse에 전달할 추가 스타일 인수\n",
    "\n",
    "    Returns:\n",
    "    - 타원을 그린 matplotlib Ellipse 객체\n",
    "    \"\"\"\n",
    "    from matplotlib.patches import Ellipse\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n",
    "\n",
    "    # 고유값의 제곱근으로 타원의 축 길이 결정\n",
    "    axis_length = n_std * np.sqrt(eigenvalues)\n",
    "\n",
    "    # 고유벡터에서 타원의 회전 각도 계산\n",
    "    angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))\n",
    "\n",
    "    # 타원 생성\n",
    "    ellipse = Ellipse(\n",
    "        xy=mean,\n",
    "        width=2 * axis_length[0],\n",
    "        height=2 * axis_length[1],\n",
    "        angle=angle,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # 타원을 플롯에 추가\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "    return ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f392e4f-2115-4b7d-87f1-32f5b7e35e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COIV\n",
      "tensor([[[1.1000, 0.0000],\n",
      "         [0.0000, 1.6000]]])\n",
      "L\n",
      "tensor([[[1.0488, 0.0000],\n",
      "         [0.0000, 1.2649]]])\n",
      "sigma points\n",
      "tensor([[[1.0000, 6.0000],\n",
      "         [1.0015, 6.0000],\n",
      "         [0.9985, 6.0000],\n",
      "         [1.0000, 6.0018],\n",
      "         [1.0000, 5.9982]]])\n",
      "transform\n",
      "tensor([[[-7.2111],\n",
      "         [-7.2099],\n",
      "         [-7.2123],\n",
      "         [-7.2121],\n",
      "         [-7.2101]]])\n",
      "tensor([[[-7.2111],\n",
      "         [-7.2099],\n",
      "         [-7.2123],\n",
      "         [-7.2121],\n",
      "         [-7.2101]]])\n",
      "means\n",
      "-7.75\n",
      "cov\n",
      "tensor([[[2.2812]]])\n"
     ]
    }
   ],
   "source": [
    "point_x, point_y = 7, 2\n",
    "N = 2\n",
    "mu_x = torch.linspace(1, 4, N)\n",
    "mu_y = torch.linspace(6, 10, N)\n",
    "\n",
    "\n",
    "vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "\n",
    "rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "sigma2_x = torch.linspace(1.1, 1.7, N)\n",
    "sigma2_y = torch.linspace(1.6, 2.4, N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "# means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "means = torch.tensor([1, 6])[None,:]\n",
    "\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "z = torch.zeros_like(pairs[0,:])\n",
    "# cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "cov = torch.tensor([[1.1, 0], [0, 1.6]])[None,:]\n",
    "\n",
    "print(\"COIV\")\n",
    "print(cov)\n",
    "chol_matrices = torch.linalg.cholesky(cov)\n",
    "print(\"L\")\n",
    "print(chol_matrices)\n",
    "# cholesky_matrix.shape\n",
    "\n",
    "\n",
    "# Unscented transformation parameters\n",
    "alpha = 1e-3  # Scale factor\n",
    "beta = 2.0    # Optimal for Gaussian distributions\n",
    "kappa = 0.0   # Secondary scaling parameter\n",
    "n = means.shape[1]\n",
    "lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "# Compute weights\n",
    "Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "Wc = Wm.clone()  # Covariance weights\n",
    "Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "# Generate sigma points for the entire batch\n",
    "scaling = torch.sqrt(n + lambda_)\n",
    "sigma_points = []\n",
    "\n",
    "# Central sigma points\n",
    "sigma_points.append(means)\n",
    "\n",
    "# Positive and negative directions\n",
    "for i in range(n):\n",
    "    sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "    sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "# Stack sigma points into a batch tensor\n",
    "sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "print(\"sigma points\")\n",
    "print(sigma_points)\n",
    "# Nonlinear transformation function (example)\n",
    "# def nonlinear_transform(x):\n",
    "#     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "def nonlinear_transform(x):\n",
    "    target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "    distance = -torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "    return distance[..., None]  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "# Apply the nonlinear transformation to all sigma points\n",
    "transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "print(\"transform\")\n",
    "print(transformed_sigma_points)\n",
    "# Compute transformed means (batch)\n",
    "print(transformed_sigma_points)\n",
    "transformed_means = torch.sum(Wm[None, :, None] * transformed_sigma_points, dim=1)\n",
    "print(\"means\")\n",
    "print(transformed_means.item())\n",
    "# Compute transformed covariances (batch)\n",
    "diff = transformed_sigma_points - transformed_means[:, None, :]\n",
    "transformed_covariances = torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "print(\"cov\")\n",
    "print(transformed_covariances)\n",
    "epsilon = torch.tensor(0.95)\n",
    "gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "transformed_means.squeeze().shape, transformed_covariances.squeeze().shape\n",
    "CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "min_idx = CVaR.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e33cd0-3a49-4491-9b59-88e4ebe9a987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means, cov\n",
      "tensor([29.1859, 40.2010]) tensor([[2.8688, 0.0000],\n",
      "        [0.0000, 0.1291]])\n",
      "0.013811349868774414\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "point_x, point_y = 30, 40\n",
    "N = 200\n",
    "mu_x = torch.linspace(12, 30, N)\n",
    "mu_y = torch.linspace(40, 60, N)\n",
    "\n",
    "\n",
    "vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "\n",
    "rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "sigma2_x = torch.linspace(0.1, 3, N)\n",
    "sigma2_y = torch.linspace(0.1, 3, N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "z = torch.zeros_like(pairs[0,:])\n",
    "cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "chol_matrices = torch.linalg.cholesky(cov)\n",
    "# cholesky_matrix.shape\n",
    "\n",
    "\n",
    "# Unscented transformation parameters\n",
    "alpha = 1e-3  # Scale factor\n",
    "beta = 2.0    # Optimal for Gaussian distributions\n",
    "kappa = 0.0   # Secondary scaling parameter\n",
    "n = means.shape[1]\n",
    "lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "# Compute weights\n",
    "Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "Wc = Wm.clone()  # Covariance weights\n",
    "Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "# Generate sigma points for the entire batch\n",
    "scaling = torch.sqrt(n + lambda_)\n",
    "sigma_points = []\n",
    "\n",
    "# Central sigma points\n",
    "sigma_points.append(means)\n",
    "\n",
    "# Positive and negative directions\n",
    "for i in range(n):\n",
    "    sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "    sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "# Stack sigma points into a batch tensor\n",
    "sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "\n",
    "# Nonlinear transformation function (example)\n",
    "# def nonlinear_transform(x):\n",
    "#     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "def nonlinear_transform(x):\n",
    "    target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "    distance = 10-torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "    return distance  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "# Apply the nonlinear transformation to all sigma points\n",
    "transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "# Compute transformed means (batch)\n",
    "transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "# Compute transformed covariances (batch)\n",
    "diff = transformed_sigma_points - transformed_means[:, None]\n",
    "transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "\n",
    "epsilon = torch.tensor(0.95)\n",
    "gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "transformed_means.squeeze().shape, transformed_covariances.squeeze().shape\n",
    "CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "max_idx = CVaR.argmax()\n",
    "print('means, cov')\n",
    "print(means[max_idx], cov[max_idx])\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57dc29e4-1a18-4879-8b24-75ca64ecb5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsilon = 0.95\n",
    "target_cdf = 0.50\n",
    "kappa = norm.pdf(norm.ppf(epsilon))/(1-epsilon)\n",
    "import pickle\n",
    "\n",
    "with open(f'../1d/a_memory_set/a_memory_{target_cdf}.pickle', 'rb') as fr:\n",
    "    a_memory = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "3a391b00-26f1-4c09-bd81-69ae9299645e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1890b0a0f4221b764122d637dc1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Major Axis (a)', min=-100.0, step=1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def plot(point_x,point_y, obs_x, obs_y, obs_sx, obs_sy):\n",
    "    N = 200\n",
    "    mu_x = torch.linspace(-25, 30, N)\n",
    "    mu_y = torch.linspace(-30, 20, N)\n",
    "    \n",
    "    \n",
    "    vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    \n",
    "    sigma2_x = torch.linspace(0.1, 3, N)\n",
    "    sigma2_y = torch.linspace(0.1, 3, N)\n",
    "\n",
    "    mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "    means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "\n",
    "    sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "    pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "    z = torch.zeros_like(pairs[0,:])\n",
    "    cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "    chol_matrices = torch.linalg.cholesky(cov)\n",
    "    print(\"DBG\")\n",
    "    print(chol_matrices.shape)\n",
    "    # cholesky_matrix.shape\n",
    "\n",
    "\n",
    "    # Unscented transformation parameters\n",
    "    alpha = 1e-3  # Scale factor\n",
    "    beta = 2.0    # Optimal for Gaussian distributions\n",
    "    kappa = 0.0   # Secondary scaling parameter\n",
    "    n = means.shape[1]\n",
    "    lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "    # Compute weights\n",
    "    Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "    Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "    Wc = Wm.clone()  # Covariance weights\n",
    "    Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "    # Generate sigma points for the entire batch\n",
    "    scaling = torch.sqrt(n + lambda_)\n",
    "    sigma_points = []\n",
    "\n",
    "    # Central sigma points\n",
    "    sigma_points.append(means)\n",
    "\n",
    "    # Positive and negative directions\n",
    "    for i in range(n):\n",
    "        sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "        sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "    # Stack sigma points into a batch tensor\n",
    "    sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "\n",
    "    # Nonlinear transformation function (example)\n",
    "    # def nonlinear_transform(x):\n",
    "    #     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "    def nonlinear_transform(x):\n",
    "        target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "        distance = 10-torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "        return distance  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "    # Apply the nonlinear transformation to all sigma points\n",
    "    transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "    # Compute transformed means (batch)\n",
    "    transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "    # Compute transformed covariances (batch)\n",
    "    diff = transformed_sigma_points - transformed_means[:, None]\n",
    "    transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "\n",
    "    epsilon = torch.tensor(0.95)\n",
    "    gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "    CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "    max_idx = CVaR.argmax()\n",
    "    print('means, cov')\n",
    "    print(means[max_idx], cov[max_idx])\n",
    "    print('max CVaR: ', CVaR.max())\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "    ax[0].add_patch(rectangle)\n",
    "    \n",
    "    plot_ellipse(means[max_idx], cov[max_idx], n_std=2, ax=ax[0])\n",
    "    \n",
    "    ax[0].scatter(point_x, point_y)\n",
    "    ax[0].set_xlim(-100, 100)\n",
    "    ax[0].set_ylim(-100, 100)\n",
    "    \n",
    "    ax[1].hist(CVaR, bins=100)\n",
    "    \n",
    "    # Calculate New CVaR\n",
    "    \n",
    "    mean = torch.tensor([mu_x.min(), mu_y.min()])[None,:]\n",
    "    cov = torch.tensor([\n",
    "        [sigma2_x.max(), 0],\n",
    "        [0, sigma2_y.max()]\n",
    "    ])[None,:]\n",
    "    \n",
    "    mean = torch.tensor([obs_x, obs_y])[None,:]\n",
    "    cov = torch.tensor([\n",
    "        [obs_sx, 0],\n",
    "        [0, obs_sy]\n",
    "    ])[None,:]\n",
    "    L = torch.linalg.cholesky(cov)\n",
    "    \n",
    "    sigma_points = list()\n",
    "    sigma_points.append(mean)\n",
    "    for i in range(n):\n",
    "        sigma_points.append(mean + scaling * L[:, :, i])\n",
    "        sigma_points.append(mean - scaling * L[:, :, i])\n",
    "    sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "    # Apply the nonlinear transformation to all sigma points\n",
    "    transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "    # Compute transformed means (batch)\n",
    "    transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "    # Compute transformed covariances (batch)\n",
    "    diff = transformed_sigma_points - transformed_means[:, None]\n",
    "    transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "    CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "    print(\"new mean, cov: \",transformed_means.squeeze(), transformed_covariances.squeeze())\n",
    "    print(\"new CVaR: \",CVaR)\n",
    "    ax[1].scatter(CVaR, 0, color='r')\n",
    "    plot_ellipse(mean[0], cov[0], n_std=2, ax=ax[0], color='green')\n",
    "\n",
    "    \n",
    "interact(\n",
    "        plot,\n",
    "        point_x=FloatSlider(min=-100, max=100, step=1, value=0, description='Major Axis (a)'),\n",
    "        point_y=FloatSlider(min=-100, max=100, step=1, value=0, description='Minor Axis (b)'),\n",
    "        obs_x=FloatSlider(min=12, max=30, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_y=FloatSlider(min=40, max=60, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_sx=FloatSlider(min=0.1, max=3, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_sy=FloatSlider(min=0.1, max=3, step=0.1, value=0, description='Minor Axis (b)'),\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd54939e-b89d-492d-b1fe-0a5a02f83b39",
   "metadata": {},
   "source": [
    "# use Mahalanobis distance for closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "2ac9f397-9e58-4930-871d-1da8b0010113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5649ca8b2e4105b39ab330b8313b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Major Axis (a)', min=-100.0, step=1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def plot(point_x,point_y):\n",
    "    N = 20\n",
    "    mu_x = torch.linspace(-25, 25, N)\n",
    "    mu_y = torch.linspace(-25, 25, N)\n",
    "    \n",
    "    \n",
    "    vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "    s_N = 10\n",
    "    sigma2_x = torch.linspace(0.1, 3, s_N)\n",
    "    sigma2_y = torch.linspace(0.1, 3, s_N)\n",
    "\n",
    "    mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "    means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()])\n",
    "\n",
    "    sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "    z = torch.zeros_like(sigma2_x_grid).flatten()\n",
    "\n",
    "    covs = torch.stack([sigma2_x_grid.flatten(), z, z, sigma2_y_grid.flatten()])\n",
    "    print(means.shape, covs.shape)\n",
    "    Mu = means.repeat(s_N * s_N, 1, 1).permute(0,2,1).transpose(0,1).flatten(0,1)\n",
    "    Sigma = covs.repeat(N * N, 1, 1).permute(0,2,1).flatten(0,1)\n",
    "\n",
    "    print(Mu.shape, Sigma.shape)\n",
    "    samples = torch.cat([Mu, Sigma], dim=1)\n",
    "    \n",
    "    mean_list = samples[:,:2]\n",
    "    cov_list = samples[:,2:].reshape(-1,2,2)\n",
    "    # mean_list = means.repeat(s_N*s_N, 1)\n",
    "    # cov_list = cov.repeat(N*N, 1, 1)\n",
    "    \n",
    "    chol_matrices = torch.linalg.cholesky(cov_list)\n",
    "    print(\"DBG\")\n",
    "    print(chol_matrices.shape)\n",
    "\n",
    "\n",
    "    # Unscented transformation parameters\n",
    "    alpha = 1e-3  # Scale factor\n",
    "    beta = 2.0    # Optimal for Gaussian distributions\n",
    "    kappa = 0.0   # Secondary scaling parameter\n",
    "    n = means.shape[0]\n",
    "    lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "    # Compute weights\n",
    "    Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "    Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "    Wc = Wm.clone()  # Covariance weights\n",
    "    Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "    # Generate sigma points for the entire batch\n",
    "    scaling = torch.sqrt(n + lambda_)\n",
    "    sigma_points = []\n",
    "\n",
    "    # Central sigma points\n",
    "    sigma_points.append(mean_list)\n",
    "\n",
    "    # Positive and negative directions\n",
    "    for i in range(n):\n",
    "        sigma_points.append(mean_list + scaling * chol_matrices[:, :, i])\n",
    "        sigma_points.append(mean_list - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "    # Stack sigma points into a batch tensor\n",
    "    sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "\n",
    "    # Nonlinear transformation function (example)\n",
    "    # def nonlinear_transform(x):\n",
    "    #     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "    def nonlinear_transform(x):\n",
    "        target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "        distance = 10-torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "        return distance  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "    # Apply the nonlinear transformation to all sigma points\n",
    "    transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "    # Compute transformed means (batch)\n",
    "    transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "    # Compute transformed covariances (batch)\n",
    "    diff = transformed_sigma_points - transformed_means[:, None]\n",
    "    transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "\n",
    "    epsilon = torch.tensor(0.95)\n",
    "    gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "    CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "    max_idx = CVaR.argmax()\n",
    "    print('means, cov')\n",
    "    print(mean_list[max_idx], cov_list[max_idx])\n",
    "    print('max CVaR: ', CVaR.max())\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "    ax[0].add_patch(rectangle)\n",
    "    \n",
    "    plot_ellipse(mean_list[max_idx], cov_list[max_idx], n_std=2, ax=ax[0])\n",
    "    \n",
    "    ax[0].scatter(point_x, point_y)\n",
    "    ax[0].set_xlim(-100, 100)\n",
    "    ax[0].set_ylim(-100, 100)\n",
    "    \n",
    "    # ax[1].hist(CVaR, bins=100)\n",
    "    \n",
    "\n",
    "    # Mahalanobis distance minimum distribution\n",
    "\n",
    "    diff = torch.tensor([point_x, point_y]) - mean_list\n",
    "    inv_cov = np.linalg.inv(cov_list)\n",
    "        \n",
    "    dist = np.sqrt(diff[:,None,:] @ inv_cov @ diff[:,None,:].permute(0,2,1))\n",
    "    print(dist.squeeze())\n",
    "    ax[1].hist(dist.squeeze(), bins=100)\n",
    "    min_dist_idx = dist.squeeze().argmin().item()\n",
    "    print(\"mahalanobis min dist: \",dist[min_dist_idx])\n",
    "    print(mean_list[min_dist_idx])\n",
    "    print(cov_list[min_dist_idx])\n",
    "    print('='*30)\n",
    "    print(diff.norm(dim=1)[min_dist_idx])\n",
    "    print(mean_list[max_idx])\n",
    "    print(cov_list[max_idx])\n",
    "    new_diff = torch.tensor([point_x, point_y]) - mean_list[max_idx]\n",
    "    print(\"new diff: \",new_diff)\n",
    "    new_inv_cov = np.linalg.inv(cov_list[max_idx])\n",
    "    new_dist = np.sqrt(new_diff @ new_inv_cov @ new_diff.T)\n",
    "    print(\"new_dist: \",new_dist)\n",
    "    \n",
    "    plot_ellipse(mean_list[min_dist_idx], cov_list[min_dist_idx], n_std=2, ax=ax[0], color='g', alpha=0.3)\n",
    "\n",
    "    \n",
    "interact(\n",
    "        plot,\n",
    "        point_x=FloatSlider(min=-100, max=100, step=1, value=0, description='Major Axis (a)'),\n",
    "        point_y=FloatSlider(min=-100, max=100, step=1, value=0, description='Minor Axis (b)'),\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "971a4311-5c7b-41b6-a1d2-a0406fc51b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-20.    -2.13]\n",
      "11.864509976512247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.864509976512247"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "point = np.array([-45,0])\n",
    "\n",
    "mean = np.array([-25,2.13])\n",
    "cov = np.array([\n",
    "    [2.9,0],\n",
    "    [0,1.6]\n",
    "])\n",
    "\n",
    "diff = point - mean\n",
    "print(diff)\n",
    "dist = diff @ np.linalg.inv(cov) @ diff.T\n",
    "print(np.sqrt(dist))\n",
    "distance.mahalanobis(point, mean, np.linalg.inv(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "671569d4-a818-4edb-b764-fb695945b204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n",
      "tensor([-25., -25.])\n",
      "tensor([[0.1000, 0.0000],\n",
      "        [0.0000, 0.1000]])\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "N = 20\n",
    "mu_x = torch.linspace(-25, 25, N)\n",
    "mu_y = torch.linspace(-25, 25, N)\n",
    "\n",
    "\n",
    "vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "\n",
    "rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "s_N = 10\n",
    "sigma2_x = torch.linspace(0.1, 3, s_N)\n",
    "sigma2_y = torch.linspace(0.1, 3, s_N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "z = torch.zeros_like(pairs[0,:])\n",
    "cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "means.shape, cov.shape\n",
    "# torch.cat((means, cov), dim=-1)\n",
    "cov_list, mean_list = cov.repeat(N * N, 1, 1), means.repeat(s_N * s_N,1)\n",
    "\n",
    "for i in range(10):\n",
    "    print(mean_list[idx])\n",
    "    print(cov_list[idx])\n",
    "    print('---'*10)\n",
    "    plot_ellipse(mean_list[idx], cov_list[idx], n_std=2, ax=ax, color='b', fill=False, alpha=0.1)\n",
    "ax.set_xlim(-30, -20)\n",
    "ax.set_ylim(-30, -20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "2a103cbe-3a78-47eb-96ac-3657086ffd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 49]) torch.Size([4, 16])\n",
      "==============================\n",
      "784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.        ],\n",
       "        [0.        , 1.        ]],\n",
       "\n",
       "       [[1.        , 0.        ],\n",
       "        [0.        , 0.59999996]],\n",
       "\n",
       "       [[1.        , 0.        ],\n",
       "        [0.        , 0.42857143]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.33333334, 0.        ],\n",
       "        [0.        , 0.59999996]],\n",
       "\n",
       "       [[0.33333334, 0.        ],\n",
       "        [0.        , 0.42857143]],\n",
       "\n",
       "       [[0.33333334, 0.        ],\n",
       "        [0.        , 0.33333334]]], dtype=float32)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 7\n",
    "mu_x = torch.linspace(0, 2, N)\n",
    "mu_y = torch.linspace(0, 2, N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing='ij')\n",
    "means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()])\n",
    "\n",
    "\n",
    "s_N = 4\n",
    "sigma2_x = torch.linspace(1, 3, s_N)\n",
    "sigma2_y = torch.linspace(1,3,s_N)\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing='ij')\n",
    "\n",
    "z = torch.zeros_like(sigma2_x_grid)\n",
    "sigma2s = torch.stack([sigma2_x_grid.flatten(), z.flatten(), z.flatten(), sigma2_y_grid.flatten()])\n",
    "\n",
    "print(means.shape, sigma2s.shape)\n",
    "Mu = means.repeat(s_N*s_N, 1, 1).permute(0,2,1).transpose(0,1).flatten(0,1)\n",
    "Sigma = sigma2s.repeat(N*N, 1, 1).permute(0,2,1).flatten(0,1)\n",
    "samples = torch.cat([Mu, Sigma], dim=1)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "print('='*30)\n",
    "print(len(samples))\n",
    "\n",
    "\n",
    "mean_list = samples[:,:2]\n",
    "cov_list = samples[:,2:].reshape(-1,2,2)\n",
    "\n",
    "np.linalg.inv(cov_list)\n",
    "# for sample in samples[:]:\n",
    "#     mu = sample[:2]\n",
    "#     Sigma = sample[2:].reshape(2,2)\n",
    "    \n",
    "#     plot_ellipse(mu, Sigma, n_std=2, ax=ax, color='b', fill=False, alpha=0.1)\n",
    "# ax.set_xlim(-10,10)\n",
    "# ax.set_ylim(-10,10)\n",
    "# plt.show()\n",
    "# means_grid, Sigma_grid = torch.meshgrid(means.flatten(), sigma2s.flatten())\n",
    "# means_grid.shape, Sigma_grid.shape\n",
    "# torch.stack([means_grid.flatten(), Sigma_grid.flatten()]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "10b7f921-e121-4e3c-b1e0-b44e60323838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5],\n",
       "        [  6,   7,   8,   9,  10,  11],\n",
       "        [ 12,  13,  14,  15,  16,  17],\n",
       "        [ 18,  19,  20,  21,  22,  23],\n",
       "        [ 24,  25,  26,  27,  28,  29],\n",
       "        [ 30,  31,  32,  33,  34,  35],\n",
       "        [ 36,  37,  38,  39,  40,  41],\n",
       "        [ 42,  43,  44,  45,  46,  47],\n",
       "        [ 48,  49,  50,  51,  52,  53],\n",
       "        [ 54,  55,  56,  57,  58,  59],\n",
       "        [ 60,  61,  62,  63,  64,  65],\n",
       "        [ 66,  67,  68,  69,  70,  71],\n",
       "        [ 72,  73,  74,  75,  76,  77],\n",
       "        [ 78,  79,  80,  81,  82,  83],\n",
       "        [ 84,  85,  86,  87,  88,  89],\n",
       "        [ 90,  91,  92,  93,  94,  95],\n",
       "        [ 96,  97,  98,  99, 100, 101],\n",
       "        [102, 103, 104, 105, 106, 107],\n",
       "        [108, 109, 110, 111, 112, 113],\n",
       "        [114, 115, 116, 117, 118, 119],\n",
       "        [120, 121, 122, 123, 124, 125],\n",
       "        [126, 127, 128, 129, 130, 131],\n",
       "        [132, 133, 134, 135, 136, 137],\n",
       "        [138, 139, 140, 141, 142, 143],\n",
       "        [144, 145, 146, 147, 148, 149],\n",
       "        [150, 151, 152, 153, 154, 155],\n",
       "        [156, 157, 158, 159, 160, 161],\n",
       "        [162, 163, 164, 165, 166, 167],\n",
       "        [168, 169, 170, 171, 172, 173],\n",
       "        [174, 175, 176, 177, 178, 179],\n",
       "        [180, 181, 182, 183, 184, 185],\n",
       "        [186, 187, 188, 189, 190, 191],\n",
       "        [192, 193, 194, 195, 196, 197],\n",
       "        [198, 199, 200, 201, 202, 203],\n",
       "        [204, 205, 206, 207, 208, 209],\n",
       "        [210, 211, 212, 213, 214, 215],\n",
       "        [216, 217, 218, 219, 220, 221],\n",
       "        [222, 223, 224, 225, 226, 227],\n",
       "        [228, 229, 230, 231, 232, 233],\n",
       "        [234, 235, 236, 237, 238, 239],\n",
       "        [240, 241, 242, 243, 244, 245],\n",
       "        [246, 247, 248, 249, 250, 251],\n",
       "        [252, 253, 254, 255, 256, 257],\n",
       "        [258, 259, 260, 261, 262, 263],\n",
       "        [264, 265, 266, 267, 268, 269],\n",
       "        [270, 271, 272, 273, 274, 275],\n",
       "        [276, 277, 278, 279, 280, 281],\n",
       "        [282, 283, 284, 285, 286, 287],\n",
       "        [288, 289, 290, 291, 292, 293],\n",
       "        [294, 295, 296, 297, 298, 299],\n",
       "        [300, 301, 302, 303, 304, 305],\n",
       "        [306, 307, 308, 309, 310, 311],\n",
       "        [312, 313, 314, 315, 316, 317],\n",
       "        [318, 319, 320, 321, 322, 323],\n",
       "        [324, 325, 326, 327, 328, 329],\n",
       "        [330, 331, 332, 333, 334, 335],\n",
       "        [336, 337, 338, 339, 340, 341],\n",
       "        [342, 343, 344, 345, 346, 347],\n",
       "        [348, 349, 350, 351, 352, 353],\n",
       "        [354, 355, 356, 357, 358, 359],\n",
       "        [360, 361, 362, 363, 364, 365],\n",
       "        [366, 367, 368, 369, 370, 371],\n",
       "        [372, 373, 374, 375, 376, 377],\n",
       "        [378, 379, 380, 381, 382, 383],\n",
       "        [384, 385, 386, 387, 388, 389],\n",
       "        [390, 391, 392, 393, 394, 395],\n",
       "        [396, 397, 398, 399, 400, 401],\n",
       "        [402, 403, 404, 405, 406, 407],\n",
       "        [408, 409, 410, 411, 412, 413],\n",
       "        [414, 415, 416, 417, 418, 419],\n",
       "        [420, 421, 422, 423, 424, 425],\n",
       "        [426, 427, 428, 429, 430, 431],\n",
       "        [432, 433, 434, 435, 436, 437],\n",
       "        [438, 439, 440, 441, 442, 443],\n",
       "        [444, 445, 446, 447, 448, 449],\n",
       "        [450, 451, 452, 453, 454, 455],\n",
       "        [456, 457, 458, 459, 460, 461],\n",
       "        [462, 463, 464, 465, 466, 467],\n",
       "        [468, 469, 470, 471, 472, 473],\n",
       "        [474, 475, 476, 477, 478, 479],\n",
       "        [480, 481, 482, 483, 484, 485]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(81*6).reshape(81, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0446e87b-a891-4851-9341-664fd75cdec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7bb4f2bafc4a449399f6e813e6a37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Major Axis (a)', max=4000000), Output()), _dom_classes=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def plot(idx):\n",
    "    N = 200\n",
    "    mu_x = torch.linspace(-25, 25, N)\n",
    "    mu_y = torch.linspace(-25, 25, N)\n",
    "    \n",
    "    \n",
    "    vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "    s_N = 10\n",
    "    sigma2_x = torch.linspace(0.1, 3, s_N)\n",
    "    sigma2_y = torch.linspace(0.1, 3, s_N)\n",
    "    \n",
    "    mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "    means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "    \n",
    "    sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "    \n",
    "    pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "    z = torch.zeros_like(pairs[0,:])\n",
    "    cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "    mean_list = means.repeat(s_N*s_N, 1)\n",
    "    cov_list = cov.repeat(N*N, 1, 1)\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    \n",
    "    \n",
    "    print(mean_list[idx])\n",
    "    print(cov_list[idx])\n",
    "    plot_ellipse(mean_list[idx], cov_list[idx], n_std=2, ax=ax, color='g')\n",
    "    ax.set_xlim(-100, 100)\n",
    "    ax.set_ylim(-100, 100)\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "        plot,\n",
    "        idx=IntSlider(min=0, max=200*200*10*10, step=1, value=0, description='Major Axis (a)'),\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153bbde8-07ee-4692-9e94-30e7fd1a50c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4495, 2.2678],\n",
       "        [3.4641, 3.4641],\n",
       "        [1.7811, 2.5461],\n",
       "        [1.2403, 2.2871]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마할라노비스 거리 계산 함수\n",
    "def mahalanobis_distance_batch(means, covs, point):\n",
    "    # 공분산 행렬의 역행렬 계산\n",
    "    cov_inv = torch.linalg.inv(covs)\n",
    "    \n",
    "    # 각 분포에 대해 마할라노비스 거리 계산\n",
    "    # (point - mean)의 차이 벡터를 구하고, 이를 공분산 역행렬로 곱함\n",
    "    diff = point - means\n",
    "    mahalanobis_distances = torch.sqrt(torch.sum(diff @ cov_inv * diff, dim=1))\n",
    "    \n",
    "    return mahalanobis_distances\n",
    "\n",
    "\n",
    "# 평균과 공분산 행렬을 4개 분포에 대해 정의\n",
    "means = torch.tensor([[3, 4], [1, 2], [5, 6], [7, 8]], dtype=torch.float32)\n",
    "covs = torch.tensor([[[4, 0], [0, 7]], \n",
    "                     [[2, 0], [0, 3]], \n",
    "                     [[6, 1], [1, 5]], \n",
    "                     [[8, 3], [3, 6]]], dtype=torch.float32)\n",
    "\n",
    "point = torch.tensor([5, 7], dtype=torch.float32)\n",
    "\n",
    "mahalanobis_distances_batch = mahalanobis_distance_batch(means, covs, point)\n",
    "\n",
    "mahalanobis_distances_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ca1d32-aa68-4740-9494-cdc72c537789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.30217289, 4.        ],\n",
       "        [1.87971629, 3.26598632],\n",
       "        [2.65832027, 4.61880215]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def mahalanobis_batch(points, means, covariances):\n",
    "    inv_covariances = np.linalg.inv(covariances)\n",
    "    distances = [distance.mahalanobis(point, mean, inv_covariances) for point, mean in zip(points, means)]\n",
    "    return distances\n",
    "\n",
    "# 점 (4, 5)\n",
    "point_batch = np.array([[4, 5]])\n",
    "\n",
    "# 여러 정규분포의 평균과 공분산\n",
    "means_batch = np.array([[7, 2], [6, 3], [8, 1]])\n",
    "covariances_batch = np.array([[[5, 0], [0, 1]], [[4, 0], [0, 2]], [[6, 0], [0, 3]]])\n",
    "\n",
    "# Mahalanobis distances 계산\n",
    "distances_batch = mahalanobis_batch(point_batch, means_batch, covariances_batch)\n",
    "\n",
    "distances_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d348163a-65f9-45bb-9fe1-4ffec65a7cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[17.1250]],\n",
      "\n",
      "        [[23.1250]]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = torch.tensor(np.array([-10.,6.]))\n",
    "\n",
    "means = torch.tensor(np.array([[1,4], [3,4]]), dtype=torch.float)\n",
    "covs = torch.tensor(\n",
    "        np.array([\n",
    "        [\n",
    "            [8,0],\n",
    "            [0,2]\n",
    "        ],\n",
    "        [\n",
    "            [8,0],\n",
    "            [0,2]\n",
    "        ]\n",
    "    ])\n",
    "    , dtype=torch.float)\n",
    "\n",
    "diff = means - point\n",
    "dist = (diff[:,None,:] @ np.linalg.inv(covs) @ diff[:,None,:].permute(0,2,1))\n",
    "print(dist)\n",
    "dist.argmin().item()\n",
    "# print((point - mean).T[:,:,None])\n",
    "# print(cov.shape)\n",
    "# print(np.linalg.inv(cov).shape)\n",
    "# print((point - mean)[:,None,:] @ np.linalg.inv(cov) @ (point - mean).T[:,:,None])\n",
    "# dist = (point - mean) @ np.linalg.inv(cov) @ (point - mean).T\n",
    "# print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f34d29c-a37b-4a3c-a6cc-7ae549081d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([11.1803, 13.1529], dtype=torch.float64),\n",
       " tensor(11.1803, dtype=torch.float64))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "diff.norm(dim=1), (point - means[0]).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf6f2fb0-eaf6-4304-80e5-2048e08b531e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_list = list()\n",
    "for i in range(50):\n",
    "    sample_list.append([-i, 0])\n",
    "    \n",
    "for i in range(50):\n",
    "    sample_list.append([-50, i])\n",
    "    \n",
    "for i in range(100):\n",
    "    sample_list.append([i-50, 50])\n",
    "    \n",
    "for i in range(100):\n",
    "    sample_list.append([50, 50-i])\n",
    "    \n",
    "for i in range(150):\n",
    "    sample_list.append([50-i, -50])\n",
    "    \n",
    "for i in range(150):\n",
    "    sample_list.append([-100, i-50])\n",
    "    \n",
    "for i in range(200):\n",
    "    sample_list.append([i-100, 100])\n",
    "    \n",
    "for i in range(200):\n",
    "    sample_list.append([100, i-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "218eb602-99dd-4546-b868-25bcf381f59f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [15:46,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from tqdm import tqdm\n",
    "\n",
    "for idx, (x,y) in tqdm(enumerate(sample_list)):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    sample = [x, y]\n",
    "    input_data = torch.tensor(cart2polar(*sample), dtype=torch.float)[None,:]\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    x_params = [pred[0][0,0], pred[1][0,0], pred[2][0,0], pred[3][0,0]]\n",
    "    y_params = [pred[0][0,1], pred[1][0,1], pred[2][0,1], pred[3][0,1]]\n",
    "\n",
    "    \n",
    "    # ambiguity set\n",
    "    ## x axis\n",
    "    mu_0, lambda_, alpha, beta = x_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    x_mu_low, x_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    ## y axis\n",
    "    mu_0, lambda_, alpha, beta = y_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    y_mu_low, y_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    vertices = [(x_mu_low, y_mu_low), (x_mu_low, y_mu_high), (x_mu_high, y_mu_high), (x_mu_high, y_mu_low)]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    # sampling\n",
    "    for _ in range(500):\n",
    "        x_dist_params = NIG_sample(x_params)\n",
    "        y_dist_params = NIG_sample(y_params)\n",
    "\n",
    "        mean = np.array([x_dist_params[0], y_dist_params[0]])\n",
    "        cov = np.array([\n",
    "            [x_dist_params[1], 0],\n",
    "            [0, y_dist_params[1]]\n",
    "        ])\n",
    "\n",
    "\n",
    "        # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "        # 1-sigma 수준에서 타원의 축 반지름 계산\n",
    "        axis_lengths = np.sqrt(eigvals)\n",
    "\n",
    "        # 타원의 각도 계산 (라디안)\n",
    "        angle = np.arctan2(eigvecs[1, 0], eigvecs[0, 0])\n",
    "\n",
    "        # 타원 좌표 생성\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)\n",
    "        ellipse = np.array([axis_lengths[0] * np.cos(theta), axis_lengths[1] * np.sin(theta)])\n",
    "\n",
    "        # 타원의 회전 적용\n",
    "        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                                     [np.sin(angle), np.cos(angle)]])\n",
    "        rotated_ellipse = rotation_matrix @ ellipse\n",
    "\n",
    "        # 타원을 평균 좌표로 이동\n",
    "        ellipse_x, ellipse_y = rotated_ellipse[0] + mean[0], rotated_ellipse[1] + mean[1]\n",
    "        if (x_mu_low < mean[0] and mean[0] < x_mu_high) and (y_mu_low < mean[1] and mean[1] < y_mu_high):\n",
    "            color = 'lime'\n",
    "            alpha = 0.1\n",
    "            label = 'in ambiguity set'\n",
    "        else:\n",
    "            color = 'skyblue'\n",
    "            alpha = 0.8\n",
    "            label = 'out of ambiguity set'\n",
    "        plt.plot(ellipse_x, ellipse_y, color=color, alpha=alpha, label=label)\n",
    "    ax.add_patch(rectangle)\n",
    "\n",
    "    plt.scatter(*sample, color='g', label='Ground Truth')\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-100, 100)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))  # 중복 제거\n",
    "\n",
    "    # 고유한 레이블만 포함하는 legend 표시\n",
    "    plt.legend(unique_labels.values(), unique_labels.keys())   \n",
    "    plt.savefig(f'record/{idx}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffbf86-ab40-434c-b110-028f71e89c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
