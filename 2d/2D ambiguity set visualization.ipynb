{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14b07ae-9304-486e-b5b5-bde410202c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/DRO-EDL/2d\n",
      "['/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/opencda/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!export PYTHONPATH=$PYTHONPATH:$(pwd)/evidential-learning-pytorch\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/work/DRO-EDL/1d/evidential-learning-pytorch')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm, invgamma\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import minimize\n",
    "from scipy.integrate import dblquad\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from edl_pytorch import NormalInvGamma, evidential_regression\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.stats import invgamma, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f23ec6-0a1f-4efd-b0d7-38bd54d9bc3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cart2polar(x,y):\n",
    "    r = (x**2 + y**2)**(1/2)\n",
    "    theta = np.arctan2(y,x)\n",
    "    return r , theta\n",
    "\n",
    "def polar2cart(r,theta):\n",
    "    x = r*np.cos(theta)\n",
    "    y = r*np.sin(theta)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656bfb3d-70b4-4d29-86a8-dba5ed6027ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 64),\n",
    "    nn.ReLU(),\n",
    "    NormalInvGamma(64, 2),\n",
    ")\n",
    "model.load_state_dict(torch.load(f'uncertain_weights/{90}.pth', weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4928fd6-de8a-4d0b-8cb6-34c80a045011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NIG_sample(params):\n",
    "    mu_0, lambda_, alpha, beta = params\n",
    "    x_sigma2_dist = invgamma(alpha, scale=beta)\n",
    "    sigma2 = x_sigma2_dist.rvs(1)\n",
    "    x_mu_dist = norm(mu_0, np.sqrt(sigma2 / lambda_))\n",
    "    mu = x_mu_dist.rvs(1)\n",
    "    return np.array([mu[0], sigma2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cf4dca-1595-440f-8047-8c1e61989bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "a_memory = dict()\n",
    "with open(f'../1d/a_memory_set/a_memory_{0.9}.pickle', 'rb') as f:\n",
    "    a_memory = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d368fff-566c-416e-a8d1-e719ff1836f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b78628b7d84da7969740013af9cec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Major Axis (a)', min=-100.0, step=1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "def plot(x, y):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    print(x, y)\n",
    "    sample = [x, y]\n",
    "    input_data = torch.tensor(cart2polar(*sample), dtype=torch.float)[None,:]\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    x_params = [pred[0][0,0], pred[1][0,0], pred[2][0,0], pred[3][0,0]]\n",
    "    y_params = [pred[0][0,1], pred[1][0,1], pred[2][0,1], pred[3][0,1]]\n",
    "\n",
    "    \n",
    "    # ambiguity set\n",
    "    ## x axis\n",
    "    mu_0, lambda_, alpha, beta = x_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    x_mu_low, x_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    ## y axis\n",
    "    mu_0, lambda_, alpha, beta = y_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    y_mu_low, y_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    vertices = [(x_mu_low, y_mu_low), (x_mu_low, y_mu_high), (x_mu_high, y_mu_high), (x_mu_high, y_mu_low)]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    # sampling\n",
    "    for _ in range(500):\n",
    "        x_dist_params = NIG_sample(x_params)\n",
    "        y_dist_params = NIG_sample(y_params)\n",
    "\n",
    "        mean = np.array([x_dist_params[0], y_dist_params[0]])\n",
    "        cov = np.array([\n",
    "            [x_dist_params[1], 0],\n",
    "            [0, y_dist_params[1]]\n",
    "        ])\n",
    "\n",
    "\n",
    "        # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "        # 1-sigma 수준에서 타원의 축 반지름 계산\n",
    "        axis_lengths = np.sqrt(eigvals)\n",
    "\n",
    "        # 타원의 각도 계산 (라디안)\n",
    "        angle = np.arctan2(eigvecs[1, 0], eigvecs[0, 0])\n",
    "\n",
    "        # 타원 좌표 생성\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)\n",
    "        ellipse = np.array([axis_lengths[0] * np.cos(theta), axis_lengths[1] * np.sin(theta)])\n",
    "\n",
    "        # 타원의 회전 적용\n",
    "        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                                     [np.sin(angle), np.cos(angle)]])\n",
    "        rotated_ellipse = rotation_matrix @ ellipse\n",
    "\n",
    "        # 타원을 평균 좌표로 이동\n",
    "        ellipse_x, ellipse_y = rotated_ellipse[0] + mean[0], rotated_ellipse[1] + mean[1]\n",
    "        if (x_mu_low < mean[0] and mean[0] < x_mu_high) and (y_mu_low < mean[1] and mean[1] < y_mu_high):\n",
    "            color = 'lime'\n",
    "            alpha = 0.1\n",
    "            label = 'in ambiguity set'\n",
    "        else:\n",
    "            color = 'skyblue'\n",
    "            alpha = 0.8\n",
    "            label = 'out of ambiguity set'\n",
    "        plt.plot(ellipse_x, ellipse_y, color=color, alpha=alpha, label=label)\n",
    "    ax.add_patch(rectangle)\n",
    "\n",
    "    plt.scatter(*sample, color='g', label='Ground Truth')\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-100, 100)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))  # 중복 제거\n",
    "\n",
    "    # 고유한 레이블만 포함하는 legend 표시\n",
    "    plt.legend(unique_labels.values(), unique_labels.keys())   \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(\n",
    "        plot,\n",
    "        x=FloatSlider(min=-100, max=100, step=1, value=0, description='Major Axis (a)'),\n",
    "        y=FloatSlider(min=-100, max=100, step=1, value=0, description='Minor Axis (b)'),\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "513b3a2c-12f2-4074-a65f-dd4ea94fcac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ellipse(mean, covariance, n_std=2, ax=None, **kwargs):\n",
    "    \"\"\"\n",
    "    평균과 공분산 행렬을 사용하여 타원을 그립니다.\n",
    "\n",
    "    Parameters:\n",
    "    - mean: 1x2 배열, 타원의 중심 (평균 벡터)\n",
    "    - covariance: 2x2 배열, 공분산 행렬\n",
    "    - n_std: float, 타원의 크기를 결정하는 표준편차의 배수 (기본값: 2)\n",
    "    - ax: matplotlib 축 객체 (기본값: None)\n",
    "    - kwargs: matplotlib.patches.Ellipse에 전달할 추가 스타일 인수\n",
    "\n",
    "    Returns:\n",
    "    - 타원을 그린 matplotlib Ellipse 객체\n",
    "    \"\"\"\n",
    "    from matplotlib.patches import Ellipse\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance)\n",
    "\n",
    "    # 고유값의 제곱근으로 타원의 축 길이 결정\n",
    "    axis_length = n_std * np.sqrt(eigenvalues)\n",
    "\n",
    "    # 고유벡터에서 타원의 회전 각도 계산\n",
    "    angle = np.degrees(np.arctan2(*eigenvectors[:, 0][::-1]))\n",
    "\n",
    "    # 타원 생성\n",
    "    ellipse = Ellipse(\n",
    "        xy=mean,\n",
    "        width=2 * axis_length[0],\n",
    "        height=2 * axis_length[1],\n",
    "        angle=angle,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    # 타원을 플롯에 추가\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "    return ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4f392e4f-2115-4b7d-87f1-32f5b7e35e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COIV\n",
      "tensor([[[1.1000, 0.0000],\n",
      "         [0.0000, 1.6000]]])\n",
      "L\n",
      "tensor([[[1.0488, 0.0000],\n",
      "         [0.0000, 1.2649]]])\n",
      "sigma points\n",
      "tensor([[[1.0000, 6.0000],\n",
      "         [1.0015, 6.0000],\n",
      "         [0.9985, 6.0000],\n",
      "         [1.0000, 6.0018],\n",
      "         [1.0000, 5.9982]]])\n",
      "transform\n",
      "tensor([[[-7.2111],\n",
      "         [-7.2099],\n",
      "         [-7.2123],\n",
      "         [-7.2121],\n",
      "         [-7.2101]]])\n",
      "tensor([[[-7.2111],\n",
      "         [-7.2099],\n",
      "         [-7.2123],\n",
      "         [-7.2121],\n",
      "         [-7.2101]]])\n",
      "means\n",
      "-7.75\n",
      "cov\n",
      "tensor([[[2.2812]]])\n"
     ]
    }
   ],
   "source": [
    "point_x, point_y = 7, 2\n",
    "N = 2\n",
    "mu_x = torch.linspace(1, 4, N)\n",
    "mu_y = torch.linspace(6, 10, N)\n",
    "\n",
    "\n",
    "vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "\n",
    "rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "sigma2_x = torch.linspace(1.1, 1.7, N)\n",
    "sigma2_y = torch.linspace(1.6, 2.4, N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "# means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "means = torch.tensor([1, 6])[None,:]\n",
    "\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "z = torch.zeros_like(pairs[0,:])\n",
    "# cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "cov = torch.tensor([[1.1, 0], [0, 1.6]])[None,:]\n",
    "\n",
    "print(\"COIV\")\n",
    "print(cov)\n",
    "chol_matrices = torch.linalg.cholesky(cov)\n",
    "print(\"L\")\n",
    "print(chol_matrices)\n",
    "# cholesky_matrix.shape\n",
    "\n",
    "\n",
    "# Unscented transformation parameters\n",
    "alpha = 1e-3  # Scale factor\n",
    "beta = 2.0    # Optimal for Gaussian distributions\n",
    "kappa = 0.0   # Secondary scaling parameter\n",
    "n = means.shape[1]\n",
    "lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "# Compute weights\n",
    "Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "Wc = Wm.clone()  # Covariance weights\n",
    "Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "# Generate sigma points for the entire batch\n",
    "scaling = torch.sqrt(n + lambda_)\n",
    "sigma_points = []\n",
    "\n",
    "# Central sigma points\n",
    "sigma_points.append(means)\n",
    "\n",
    "# Positive and negative directions\n",
    "for i in range(n):\n",
    "    sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "    sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "# Stack sigma points into a batch tensor\n",
    "sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "print(\"sigma points\")\n",
    "print(sigma_points)\n",
    "# Nonlinear transformation function (example)\n",
    "# def nonlinear_transform(x):\n",
    "#     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "def nonlinear_transform(x):\n",
    "    target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "    distance = -torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "    return distance[..., None]  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "# Apply the nonlinear transformation to all sigma points\n",
    "transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "print(\"transform\")\n",
    "print(transformed_sigma_points)\n",
    "# Compute transformed means (batch)\n",
    "print(transformed_sigma_points)\n",
    "transformed_means = torch.sum(Wm[None, :, None] * transformed_sigma_points, dim=1)\n",
    "print(\"means\")\n",
    "print(transformed_means.item())\n",
    "# Compute transformed covariances (batch)\n",
    "diff = transformed_sigma_points - transformed_means[:, None, :]\n",
    "transformed_covariances = torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "print(\"cov\")\n",
    "print(transformed_covariances)\n",
    "epsilon = torch.tensor(0.95)\n",
    "gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "transformed_means.squeeze().shape, transformed_covariances.squeeze().shape\n",
    "CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "min_idx = CVaR.argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "296b15e4-286e-4f15-9d71-ecdd5dfd40a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-986894.0625,  246723.7656,  246723.7656,  246723.7656,  246723.7656])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "27e21a0d-0aad-4a40-92d2-d9e52a1b46f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246723.765625"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (2 * (n + lambda_))\n",
    "(1 / (2*(2 + lambda_))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b6e33cd0-3a49-4491-9b59-88e4ebe9a987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means, cov\n",
      "tensor([29.1859, 40.2010]) tensor([[2.8688, 0.0000],\n",
      "        [0.0000, 0.1291]])\n",
      "0.004408836364746094\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "point_x, point_y = 30, 40\n",
    "N = 200\n",
    "mu_x = torch.linspace(12, 30, N)\n",
    "mu_y = torch.linspace(40, 60, N)\n",
    "\n",
    "\n",
    "vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "\n",
    "rectangle = Polygon(vertices, closed=True, color='red')\n",
    "\n",
    "sigma2_x = torch.linspace(0.1, 3, N)\n",
    "sigma2_y = torch.linspace(0.1, 3, N)\n",
    "\n",
    "mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "\n",
    "sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "z = torch.zeros_like(pairs[0,:])\n",
    "cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "chol_matrices = torch.linalg.cholesky(cov)\n",
    "# cholesky_matrix.shape\n",
    "\n",
    "\n",
    "# Unscented transformation parameters\n",
    "alpha = 1e-3  # Scale factor\n",
    "beta = 2.0    # Optimal for Gaussian distributions\n",
    "kappa = 0.0   # Secondary scaling parameter\n",
    "n = means.shape[1]\n",
    "lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "# Compute weights\n",
    "Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "Wc = Wm.clone()  # Covariance weights\n",
    "Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "# Generate sigma points for the entire batch\n",
    "scaling = torch.sqrt(n + lambda_)\n",
    "sigma_points = []\n",
    "\n",
    "# Central sigma points\n",
    "sigma_points.append(means)\n",
    "\n",
    "# Positive and negative directions\n",
    "for i in range(n):\n",
    "    sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "    sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "# Stack sigma points into a batch tensor\n",
    "sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "\n",
    "# Nonlinear transformation function (example)\n",
    "# def nonlinear_transform(x):\n",
    "#     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "def nonlinear_transform(x):\n",
    "    target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "    distance = 10-torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "    return distance  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "# Apply the nonlinear transformation to all sigma points\n",
    "transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "# Compute transformed means (batch)\n",
    "transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "# Compute transformed covariances (batch)\n",
    "diff = transformed_sigma_points - transformed_means[:, None]\n",
    "transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "\n",
    "epsilon = torch.tensor(0.95)\n",
    "gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "transformed_means.squeeze().shape, transformed_covariances.squeeze().shape\n",
    "CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "max_idx = CVaR.argmax()\n",
    "print('means, cov')\n",
    "print(means[max_idx], cov[max_idx])\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "57dc29e4-1a18-4879-8b24-75ca64ecb5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epsilon = 0.95\n",
    "target_cdf = 0.50\n",
    "kappa = norm.pdf(norm.ppf(epsilon))/(1-epsilon)\n",
    "import pickle\n",
    "\n",
    "with open(f'../1d/a_memory_set/a_memory_{target_cdf}.pickle', 'rb') as fr:\n",
    "    a_memory = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3a391b00-26f1-4c09-bd81-69ae9299645e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6853e1f32fe64e7c89812d4d81331ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Major Axis (a)', min=-100.0, step=1.0), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib.patches import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "def plot(point_x,point_y, obs_x, obs_y, obs_sx, obs_sy):\n",
    "    N = 200\n",
    "    mu_x = torch.linspace(12, 30, N)\n",
    "    mu_y = torch.linspace(40, 60, N)\n",
    "    \n",
    "    \n",
    "    vertices = [(mu_x.min(), mu_y.min()), (mu_x.min(), mu_y.max()), (mu_x.max(), mu_y.max()), (mu_x.max(), mu_y.min())]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    \n",
    "    sigma2_x = torch.linspace(0.1, 3, N)\n",
    "    sigma2_y = torch.linspace(0.1, 3, N)\n",
    "\n",
    "    mu_x_grid, mu_y_grid = torch.meshgrid(mu_x, mu_y, indexing=\"ij\")\n",
    "    means = torch.stack([mu_x_grid.flatten(), mu_y_grid.flatten()]).T\n",
    "\n",
    "    sigma2_x_grid, sigma2_y_grid = torch.meshgrid(sigma2_x, sigma2_y, indexing=\"ij\")\n",
    "\n",
    "    pairs = torch.stack([sigma2_x_grid.flatten(), sigma2_y_grid.flatten()])\n",
    "    z = torch.zeros_like(pairs[0,:])\n",
    "    cov = torch.stack([pairs[0,:], z, z, pairs[1,:]], dim=0).reshape(2,2,-1).permute(2,0,1)\n",
    "\n",
    "    chol_matrices = torch.linalg.cholesky(cov)\n",
    "    # cholesky_matrix.shape\n",
    "\n",
    "\n",
    "    # Unscented transformation parameters\n",
    "    alpha = 1e-3  # Scale factor\n",
    "    beta = 2.0    # Optimal for Gaussian distributions\n",
    "    kappa = 0.0   # Secondary scaling parameter\n",
    "    n = means.shape[1]\n",
    "    lambda_ = torch.tensor(alpha**2 * (n + kappa) - n, dtype=torch.float)\n",
    "\n",
    "    # Compute weights\n",
    "    Wm = torch.full((2 * n + 1,), 1 / (2 * (n + lambda_)))  # Mean weights\n",
    "    Wm[0] = lambda_ / (n + lambda_)\n",
    "\n",
    "    Wc = Wm.clone()  # Covariance weights\n",
    "    Wc[0] += 1 - alpha**2 + beta\n",
    "\n",
    "    # Generate sigma points for the entire batch\n",
    "    scaling = torch.sqrt(n + lambda_)\n",
    "    sigma_points = []\n",
    "\n",
    "    # Central sigma points\n",
    "    sigma_points.append(means)\n",
    "\n",
    "    # Positive and negative directions\n",
    "    for i in range(n):\n",
    "        sigma_points.append(means + scaling * chol_matrices[:, :, i])\n",
    "        sigma_points.append(means - scaling * chol_matrices[:, :, i])\n",
    "\n",
    "    # Stack sigma points into a batch tensor\n",
    "    sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "\n",
    "    # Nonlinear transformation function (example)\n",
    "    # def nonlinear_transform(x):\n",
    "    #     return torch.stack([x[..., 0]**2, torch.sin(x[..., 1])], dim=-1)\n",
    "    def nonlinear_transform(x):\n",
    "        target = torch.tensor([point_x, point_y])  # Point (3, 4)\n",
    "        distance = 10-torch.sqrt(torch.sum((x - target)**2, dim=-1))  # Euclidean distance\n",
    "        return distance  # Add last dimension for compatibility\n",
    "\n",
    "\n",
    "    # Apply the nonlinear transformation to all sigma points\n",
    "    transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "    # Compute transformed means (batch)\n",
    "    transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "    # Compute transformed covariances (batch)\n",
    "    diff = transformed_sigma_points - transformed_means[:, None]\n",
    "    transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "\n",
    "    epsilon = torch.tensor(0.95)\n",
    "    gamma = torch.sqrt(epsilon / (1-epsilon))\n",
    "    CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "    max_idx = CVaR.argmax()\n",
    "    print('means, cov')\n",
    "    print(means[max_idx], cov[max_idx])\n",
    "    print('max CVaR: ', CVaR.max())\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(16,8))\n",
    "    ax[0].add_patch(rectangle)\n",
    "    \n",
    "    plot_ellipse(means[max_idx], cov[max_idx], n_std=2, ax=ax[0])\n",
    "    \n",
    "    ax[0].scatter(point_x, point_y)\n",
    "    ax[0].set_xlim(-100, 100)\n",
    "    ax[0].set_ylim(-100, 100)\n",
    "    \n",
    "    ax[1].hist(CVaR, bins=100)\n",
    "    \n",
    "    # Calculate New CVaR\n",
    "    \n",
    "    mean = torch.tensor([mu_x.min(), mu_y.min()])[None,:]\n",
    "    cov = torch.tensor([\n",
    "        [sigma2_x.max(), 0],\n",
    "        [0, sigma2_y.max()]\n",
    "    ])[None,:]\n",
    "    \n",
    "    mean = torch.tensor([obs_x, obs_y])[None,:]\n",
    "    cov = torch.tensor([\n",
    "        [obs_sx, 0],\n",
    "        [0, obs_sy]\n",
    "    ])[None,:]\n",
    "    L = torch.linalg.cholesky(cov)\n",
    "    \n",
    "    sigma_points = list()\n",
    "    sigma_points.append(mean)\n",
    "    for i in range(n):\n",
    "        sigma_points.append(mean + scaling * L[:, :, i])\n",
    "        sigma_points.append(mean - scaling * L[:, :, i])\n",
    "    sigma_points = torch.stack(sigma_points, dim=1)  # Shape: (batch, 2n+1, n)\n",
    "    # Apply the nonlinear transformation to all sigma points\n",
    "    transformed_sigma_points = nonlinear_transform(sigma_points)\n",
    "\n",
    "    # Compute transformed means (batch)\n",
    "    transformed_means = torch.sum(Wm[None, :] * transformed_sigma_points, dim=1)\n",
    "\n",
    "    # Compute transformed covariances (batch)\n",
    "    diff = transformed_sigma_points - transformed_means[:, None]\n",
    "    transformed_variances = torch.sum(Wc[None, :] * diff**2, dim=1)#torch.einsum('bij,bi,bik->bjk', diff, Wc[None], diff)\n",
    "    CVaR = transformed_means.squeeze() + gamma * transformed_covariances.squeeze()\n",
    "    print(\"new mean, cov: \",transformed_means.squeeze(), transformed_covariances.squeeze())\n",
    "    print(\"new CVaR: \",CVaR)\n",
    "    ax[1].scatter(CVaR, 0, color='r')\n",
    "    plot_ellipse(mean[0], cov[0], n_std=2, ax=ax[0], color='green')\n",
    "\n",
    "    \n",
    "interact(\n",
    "        plot,\n",
    "        point_x=FloatSlider(min=-100, max=100, step=1, value=0, description='Major Axis (a)'),\n",
    "        point_y=FloatSlider(min=-100, max=100, step=1, value=0, description='Minor Axis (b)'),\n",
    "        obs_x=FloatSlider(min=12, max=30, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_y=FloatSlider(min=40, max=60, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_sx=FloatSlider(min=0.1, max=3, step=0.1, value=0, description='Minor Axis (b)'),\n",
    "        obs_sy=FloatSlider(min=0.1, max=3, step=0.1, value=0, description='Minor Axis (b)'),\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf6f2fb0-eaf6-4304-80e5-2048e08b531e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_list = list()\n",
    "for i in range(50):\n",
    "    sample_list.append([-i, 0])\n",
    "    \n",
    "for i in range(50):\n",
    "    sample_list.append([-50, i])\n",
    "    \n",
    "for i in range(100):\n",
    "    sample_list.append([i-50, 50])\n",
    "    \n",
    "for i in range(100):\n",
    "    sample_list.append([50, 50-i])\n",
    "    \n",
    "for i in range(150):\n",
    "    sample_list.append([50-i, -50])\n",
    "    \n",
    "for i in range(150):\n",
    "    sample_list.append([-100, i-50])\n",
    "    \n",
    "for i in range(200):\n",
    "    sample_list.append([i-100, 100])\n",
    "    \n",
    "for i in range(200):\n",
    "    sample_list.append([100, i-100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "218eb602-99dd-4546-b868-25bcf381f59f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [15:46,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from tqdm import tqdm\n",
    "\n",
    "for idx, (x,y) in tqdm(enumerate(sample_list)):\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    sample = [x, y]\n",
    "    input_data = torch.tensor(cart2polar(*sample), dtype=torch.float)[None,:]\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_data)\n",
    "    x_params = [pred[0][0,0], pred[1][0,0], pred[2][0,0], pred[3][0,0]]\n",
    "    y_params = [pred[0][0,1], pred[1][0,1], pred[2][0,1], pred[3][0,1]]\n",
    "\n",
    "    \n",
    "    # ambiguity set\n",
    "    ## x axis\n",
    "    mu_0, lambda_, alpha, beta = x_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    x_mu_low, x_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    ## y axis\n",
    "    mu_0, lambda_, alpha, beta = y_params\n",
    "    try:\n",
    "        zx, zy = a_memory[float(f'{alpha:.02f}')]\n",
    "    except:\n",
    "        zx, zy = a_memory[float(f'{1.01}')]\n",
    "    delta = zx / np.sqrt(lambda_/beta)\n",
    "    y_mu_low, y_mu_high = mu_0 - delta, mu_0 + delta\n",
    "    \n",
    "    vertices = [(x_mu_low, y_mu_low), (x_mu_low, y_mu_high), (x_mu_high, y_mu_high), (x_mu_high, y_mu_low)]\n",
    "    \n",
    "    rectangle = Polygon(vertices, closed=True, color='red')\n",
    "    # sampling\n",
    "    for _ in range(500):\n",
    "        x_dist_params = NIG_sample(x_params)\n",
    "        y_dist_params = NIG_sample(y_params)\n",
    "\n",
    "        mean = np.array([x_dist_params[0], y_dist_params[0]])\n",
    "        cov = np.array([\n",
    "            [x_dist_params[1], 0],\n",
    "            [0, y_dist_params[1]]\n",
    "        ])\n",
    "\n",
    "\n",
    "        # 공분산 행렬의 고유값과 고유벡터 계산\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "        # 1-sigma 수준에서 타원의 축 반지름 계산\n",
    "        axis_lengths = np.sqrt(eigvals)\n",
    "\n",
    "        # 타원의 각도 계산 (라디안)\n",
    "        angle = np.arctan2(eigvecs[1, 0], eigvecs[0, 0])\n",
    "\n",
    "        # 타원 좌표 생성\n",
    "        theta = np.linspace(0, 2 * np.pi, 100)\n",
    "        ellipse = np.array([axis_lengths[0] * np.cos(theta), axis_lengths[1] * np.sin(theta)])\n",
    "\n",
    "        # 타원의 회전 적용\n",
    "        rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "                                     [np.sin(angle), np.cos(angle)]])\n",
    "        rotated_ellipse = rotation_matrix @ ellipse\n",
    "\n",
    "        # 타원을 평균 좌표로 이동\n",
    "        ellipse_x, ellipse_y = rotated_ellipse[0] + mean[0], rotated_ellipse[1] + mean[1]\n",
    "        if (x_mu_low < mean[0] and mean[0] < x_mu_high) and (y_mu_low < mean[1] and mean[1] < y_mu_high):\n",
    "            color = 'lime'\n",
    "            alpha = 0.1\n",
    "            label = 'in ambiguity set'\n",
    "        else:\n",
    "            color = 'skyblue'\n",
    "            alpha = 0.8\n",
    "            label = 'out of ambiguity set'\n",
    "        plt.plot(ellipse_x, ellipse_y, color=color, alpha=alpha, label=label)\n",
    "    ax.add_patch(rectangle)\n",
    "\n",
    "    plt.scatter(*sample, color='g', label='Ground Truth')\n",
    "    plt.xlim(-100, 100)\n",
    "    plt.ylim(-100, 100)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = dict(zip(labels, handles))  # 중복 제거\n",
    "\n",
    "    # 고유한 레이블만 포함하는 legend 표시\n",
    "    plt.legend(unique_labels.values(), unique_labels.keys())   \n",
    "    plt.savefig(f'record/{idx}.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffbf86-ab40-434c-b110-028f71e89c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
